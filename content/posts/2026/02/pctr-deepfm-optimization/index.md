---
title: "流量是垃圾，但“中国”太香了？DeepFM 模型眼里的地域偏见"
date: 2026-02-15T16:00:00+08:00
tags:
- deepfm
- pctr
- machine-learning
- adtech
categories:
- adtech
comment: true
featuredImagePreview: assets/cover-preview.jpg
---

> 上一回，我的逻辑回归（LR）模型因为“特征独立假设”翻车了，把垃圾流量当成了宝。为了雪耻，我祭出了杀手锏——**DeepFM**。期待它能用深度学习的“上帝视角”，看穿那些复杂特征组合背后的真相。结果模型训练完一跑，我又一次陷入了沉思：即使我给垃圾流量注入了负面偏见，它的预测值依然坚挺。这一次，不再是算法的无能，而是数据告诉了我一个残酷的真相：在绝对的“地域红利”面前，细枝末节的缺点真的可以被原谅。

<!--more-->

![DeepFM Architecture](assets/cover.jpg)

## 从 LR 到 DeepFM：鸟枪换炮

LR 吃亏在只能做加法。为了让模型学会“思考”特征之间的化学反应，我引入了 DeepFM。它有两个强力组件：
1.  **FM 组件**：专门负责二阶特征交叉，自动学习“小米+UC浏览器”这种组合的权重。
2.  **Deep 组件**：一个多层神经网络（DNN），负责挖掘更高阶的非线性关系。

我配置了 16 维的隐向量（Embedding Dim），并搭建了一个 `[128, 64, 32]` 的三层神经网络。这配置，放在这种规模的数据集上，绝对算得上是“杀鸡用牛刀”。

## 第一轮测试：略显尴尬的起步

为了先跑通流程，我设置了一组比较“保守”的参数：
*   `EMBEDDING_DIM`: 8
*   `DNN_HIDDEN_UNITS`: [64, 32]
*   `DNN_DROPOUT`: 0.5

训练过程波澜不惊，但跑出来的预测结果却让我眉头一皱：

```
🚀 DeepFM Serving Verification Results (First Round):
--------------------------------------------------
Scenario                           pCTR
🔥 爆款组合 (Camp 1, Creat 5...)     7.57%
💩 低效流量 (Xiaomi + UC Browser)    0.56%
😐 基准参考 (普通用户)              5.30%
--------------------------------------------------
```

这个结果**不太对劲**。
虽然“爆款”确实比“基准”高，而“低效”也只有 0.56%，看起来排序是没问题的。
但是！**基准参考值高达 5.30%！**

要知道，我们的全局平均点击率（Base CTR）设定的是 **2%** 左右。一个普普通通的用户预测出 5.3% 的点击率，说明模型整体 **高估（Over-estimation）** 了。这也导致“爆款”虽然高，但也只有 7.57%，并没有拉开足够的差距。

## 第二轮优化：参数与数据的双重调整

为了解决“高估”的问题，并进一步挖掘特征潜力，我决定“加大药量”：
1.  **提升容量**：将 `EMBEDDING_DIM` 翻倍至 **16**，隐向量能容纳更多信息。
2.  **加深网络**：DNN调整为 `[128, 64, 32]`，增强非线性拟合能力。
3.  **降低 Dropout**：调整为 0.15，让模型学得更“实”一些。

同时，我给训练数据做了一些微调，确保正负样本的分布更贴近真实业务场景。

再次训练后，新的结果出炉了：

```
🚀 DeepFM Serving Verification Results (Second Round):
--------------------------------------------------
Scenario                           pCTR
🔥 爆款组合 (Camp 1, Creat 5...)     25.4482%
💩 低效流量 (Xiaomi + UC Browser)    8.1655%
😐 基准参考 (普通用户)              2.0014%
--------------------------------------------------
```

### 喜忧参半的结果

**喜讯**是：模型终于“开窍”了！
*   **爆款识别精准**：预测值从 LR 时代的 7% 飙升到了 **25.45%**。这说明 DeepFM 极其敏锐地捕捉到了 Campaign 1 + Creative 5 这个黄金组合的价值。
*   **基准回归正常**：普通用户的预测值稳稳落在 **2.00%**，完美复刻了我们设定的全局基准点击率。

**疑点**是：那个 **“低效流量”**，为什么还有 **8.17%**？
这明明是我刻意构造的垃圾组合（小米+UC），按理说应该被打入冷宫才对。怎么它的得分比基准用户（2.00%）还高出 4 倍？

## 深度尸检：地域红利的霸权

是不是模型又傻了？不，经过再次深度分析，我发现**模型没傻，它只是太“现实”了**。

让我们看看这组“低效流量”的成分：
*   **设备**：Xiaomi（负分）
*   **浏览器**：UC（负分）
*   **国家**：**CN（中国）**

而在我的训练数据里，**CN 的整体点击率远高于其他国家**。

DeepFM 的逻辑是这样的：
> “虽然这个用户用的是小米，浏览器也是 UC，这俩确实减分。但是！他来自**中国**啊！在中国，随随便便一个点击的概率都比美国（US）高太多了。这点设备的减分，根本抵消不了‘生在中国’带来的巨大加分。”

这就是深度学习揭示的**特征权重霸权**：当一个高频特征（如国家）的信号强度足以碾压其他长尾特征（如设备型号）时，模型就会表现出这种“大局观”。

它在告诉我：**在绝对的流量红利面前，设备差一点，真的没关系。**

## 相对值的胜利

如果我们换个角度看，其实 DeepFM 已经尽力了。

*   同样是 **CN** 环境下的流量：
    *   **爆款组合**：25.45%
    *   **低效组合**：8.17%

**看！在同一起跑线上，DeepFM 已经把垃圾流量的得分砍掉了 2/3！** 这说明它成功识别出了“小米+UC”的负面影响。只是因为“中国”这个底座太高了（Base Score High），所以即便砍掉 2/3，剩下的绝对值依然比美国的普通用户（Base Score Low）要高。

## 结语

这次 DeepFM 的实验，不仅让我见识了深度模型的威力，更给我上了一堂生动的数据科学课：

1.  **模型不撒谎**：它忠实地反映了数据中的概率分布。如果你觉得结果反直觉，通常是因为你的直觉忽略了某些背景概率（Base Rate）。
2.  **绝对值 vs 相对值**：在跨地区、跨场景比较 pCTR 时，直接比绝对值往往会陷入误区。更科学的方法是看 **Lift（提升度）** 或者在同维度下进行 AB Test。

现在的 DeepFM 模型，已经是一个能够精准识别爆款（25% pCTR）的“印钞机”了。下一步，我准备把这个大家伙导出成 ONNX，塞进 Node.js 里，看看它的推理速度能不能跟上 RTB 的节奏！
