---
title: "我的模型是个“种族主义者”？记一次 LR 算法在广告推荐中的翻车现场"
date: 2026-02-14T15:00:00+08:00
tags:
- adtech
- machine-learning
- pctr
categories:
- adtech
comment: true
featuredImagePreview: assets/cover-preview.jpg
---

> 最近我在给 OpenAdServer 搞 pCTR（点击率预测）模型，心想先弄个 Logistic Regression (LR) 跑通流程。我洋洋洒洒造了 20 万条模拟数据，还精心地埋了几条“主线剧情”，比如某个国家的特定设备点击率特高，某个渠道的特定广告位点击率特低。结果模型训练出来一看权重，我傻眼了：它居然变成了一个只看国籍的“种族主义者”！明明是烂流量，只因为来自高权重的国家，预测分比爆款还高。这到底是人性的扭曲还是算法的沦丧？

<!--more-->

![LR vs FM Feature Interaction](assets/cover.jpg)

## 精心设计的“剧本”

为了验证模型的有效性，我没有直接使用随机数据，而是按照业务逻辑构造了一个“剧本”。在这个剧本里，我有三类典型的流量：

1.  **🔥 爆款组合**：Campaign 1 + Creative 5，投在页脚（Footer）广告位上，**点击率爆表**。
2.  **💩 低效流量**：小米手机 + UC 浏览器，投在侧边栏，**点击率极低**。
3.  **😐 基准参考**：普通的三星手机用户，各项指标平平无奇。

我满心欢喜地把这些数据喂给 LR 模型，期待它能像神探夏洛克一样，一眼识破“低效流量”的伪装。

## 现实的打脸：模型“瞎”了

训练过程看起来一切正常，Loss 稳步下降，准确率也还凑合。但是，当我把那三个典型场景丢进去做预测时，结果给了我当头一棒：

```
Scenario                           pCTR
🔥 爆款组合 (Camp 1, Creat 5...)     2.91%
💩 低效流量 (Xiaomi + UC Browser)    3.77%  <-- ？！
😐 基准参考 (普通用户)              0.39%
```

等等！**为什么“低效流量”的预测点击率（3.77%）比“爆款组合”（2.91%）还要高？！**

难道我的造数脚本写反了？我反复检查，确认 `xiaomi + uc browser` 的点击率确实设定得很低。那问题只能出在模型身上。

## 案情复盘：权重的秘密

为了查明真相，我把模型里每一个特征的权重都扒了出来，做了一番“尸检”。

### 1. 疯狂的地域加成

首先，我发现 `Country: CN`（中国）的权重高得离谱，达到了 **+1.31**。而 `Country: US`（美国）的权重却是负的 **-1.35**。

### 2. 被淹没的细节

再看“低效流量”的特征组合：
*   `Device: xiaomi` 的权重很小，甚至在负权重榜单前十都排不进（估计在 -0.1 左右）。
*   `OS: android` 的权重是 **-1.38**。

模型的计算逻辑变成了这样简单的加减法：

> **💩 低效流量得分** = CN (+1.31) + Xiaomi (-0.1) + Android (-1.38) ... **≈ 正分**

而我的“爆款组合”呢？虽然 Creative 5 很强，但因为它如果不幸发生在美国（US），就要先背上 **-1.35** 的债务。

> **🔥 爆款组合得分** = US (-1.35) + Creative 5 (+1.0) ... **≈ 负分**

**真相大白**：我的 LR 模型变成了一个彻底的“地图炮”。它认为只要是中国的流量就该点，完全忽略了“小米手机在用 UC 浏览器”这个具体的、细微的组合其实是垃圾流量的事实。它被国家这个**高频特征**彻底主导了。

## 致命缺陷：LR 不懂“组合拳”

这次翻车现场，血淋淋地揭示了 Logistic Regression 在推荐系统中的最大死穴：**特征独立性假设**。

LR 是一个**线性模型**。在它的世界里，特征之间是老死不相往来的。
* 它知道“中国”是好的。
* 它知道“小米”稍微有点不好。
* 但它**不知道**“中国的+小米”在一起会发生什么化学反应。

它只能做加法，无法理解：**“虽然 CN 是加分的，但如果 CN + Xiaomi + UC Browser 同时出现，就应该是减分的。”** 这就是所谓的 **特征交叉（Feature Interaction）** 缺失。

## 破局：FM (Factorization Machines)

要解决这个问题，我们不能再让模型只做加法了。我们需要它学会“乘法”，学会看**组合**。

这就轮到 **Factorization Machines (FM)** 出场了。

FM 的核心思想是：**给每一个特征分配一个隐向量（Embedding Vector）。当两个特征同时出现时，计算这两个向量的内积，作为它们“组合”的权重。**

*   如果是 LR：得分 = $w_{CN} + w_{Xiaomi}$
*   如果是 FM：得分 = $w_{CN} + w_{Xiaomi} + <V_{CN}, V_{Xiaomi}>$

有了后面那发子弹，当模型发现“CN”和“Xiaomi”凑一对时效果很差，它就会把 $<V_{CN}, V_{Xiaomi}>$ 训练成一个大负数。这样，即使 $w_{CN}$ 再高，也会被这个组合项给拉下来！

## 结语

这次 LR 的翻车经历虽然尴尬，但却是一次绝佳的教科书式案例。它让我深刻理解了为什么工业界的推荐系统都要上 DeepFM、DCN 这些复杂的模型。

不是为了炫技，而是因为**现实世界的数据逻辑，从来都不是线性的。**

下一步，我准备把我的 PyTorch 代码升级一下，引入 Embedding 层实现 FM 甚至 DeepFM。到时候我们再看看，那个“小米+UC”的组合还能不能骗过模型的眼睛！
