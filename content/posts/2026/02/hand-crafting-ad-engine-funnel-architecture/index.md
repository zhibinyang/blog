---
title: "手搓一个广告引擎：为什么大厂都爱“漏斗”架构？"
date: 2026-02-01T22:25:03+08:00
draft: false
tags:
- adtech
- architecture
- openadserver
- nestjs
categories:
- adtech
comment: true
featuredImagePreview: "assets/cover-preview.jpg"
---

> 为了推进我的 [2026 AdTech Sandbox]({{< ref "posts/2026/01/adtech-sandbox-2026" >}}) 计划，构建一个全链路的数字营销实验环境，我最近开始着手拆解 OpenAdServer 这个开源项目。
>
> 我的目标是将这个 Python 写的老项目重构成 NestJS 版本，作为我 Sandbox 中的核心广告引擎。本以为这只是一次简单的“语言翻译”工作——把 Python 的蛇形命名改成 TypeScript 的驼峰，把 Flask 换成 NestJS 的模块。
> 但当我重写到 `src/modules/engine/pipeline` 这个目录时，我突然意识到，自己正在重新“发明”一个极其经典的架构。
>
> 那些原本散落在各个文件里的逻辑：从缓存捞数据、判断预算、算 CTR、排序……当我把它们按顺序梳理成 5 个 NestJS Service 时，一个标准的、教科书级别的“漏斗架构”（Funnel Architecture）赫然出现在眼前。
>
> 这篇文章不谈具体的代码语法，咱们来聊聊为什么在这个星球上，几乎所有的主流广告引擎（无论是 Google、Meta 还是字节跳动）都长这个样子。

![cover](assets/cover.jpg)

## “算力不可能三角”与漏斗的诞生

想象一下，你作为一个广告平台，每秒钟可能有数十万次请求打过来。而你的数据库里躺着几百万、甚至上千万的广告创意。

最完美的情况是什幺？
对于每一个请求，我们把数据库里的一千万个广告都拿出来，每一个都跑一遍最复杂的深度学习模型，精准算出它对这个用户的点击率（pCTR）和转化率（pCVR），然后算个 eCPM 排序，选出最好的那个。

但这在物理上是不可能的。
*   **候选集太大**：一千万个广告。
*   **模型太慢**：一个复杂的 DNN 模型预测一次可能需要几毫秒。
*   **响应太快**：用户刷新页面的耐心只有 100~200 毫秒。

既要覆盖全量数据，又要用复杂模型精准预估，还要在毫秒级返回——这是一个“不可能三角”。

为了解决这个问题，聪明的工程师们发明了**“漏斗模型”**。既然不能对所有广告做精细计算，那我们就分阶段处理：**刚开始人多（广告多），用简单的规则快速筛；越往后人少（广告少），用复杂的模型精细算。**

在我的重构代码中，这个漏斗被清晰地拆解为 5 个步骤。

## 1. 检索 (Retrieval)：宁可错杀，不可放过

**行业术语**：召回 (Recall / Retrieval)
**代码实现**：`1-retrieval.service.ts`

这是漏斗的开口。在这个阶段，我们的目标不是“准”，而是“快”和“全”。

你需要从百万级的广告库里，快速圈定这几千个可能相关的广告。我的代码里虽然只是简单的缓存查询，但本质上这里通常对应着**倒排索引**（Inverted Index）或者现在流行的**向量检索**（ANN）。

这时候不能用复杂的模型，甚至连数据库的 `LIKE` 查询都嫌慢。我们通过 TargetingMatcher 检查用户画像，只保留那些“逻辑上可能”的广告。

*   **输入**：10,000,000+ 候选
*   **输出**：~1,000 候选

## 2. 过滤 (Filter)：一票否决权

**行业术语**：硬过滤 (Hard Filtering)
**代码实现**：`2-filter.service.ts`

有些规则是不能商量的。
比如，广告主的预算花完了吗？（Budget Check）
这个用户今天已经看过这个广告太多次了吗？（Frequency Capping）

这些检查必须是“硬性”的。不管你的广告多有吸引力，只要没钱了，或者违规了，就必须直接踢出局。在这个阶段，我通过 Redis Pipeline 并行处理，快速剔除掉无效的候选。

*   **输入**：~1,000 候选
*   **输出**：~500 候选

## 3. 预估 (Prediction)：算力的燃烧

**行业术语**：精排打分 (Scoring / Inference)
**代码实现**：`3-prediction.service.ts`

到了这步，候选只剩下几百个了，终于可以上“重武器”了。
这是整个引擎最耗算力的地方。我们需要预估两个核心概率：
1.  **pCTR (Predicted Click-Through Rate)**：用户会点的概率。
2.  **pCVR (Predicted Conversion Rate)**：用户点了之后会买的概率。

在我的玩具代码里，这里目前是一个模拟实现（加了点随机噪声）。但在生产环境，这里通常调用的是 ONNX Runtime 或者 TensorFlow Serving，运行的是像 DeepFM、DIN 这样庞大的深度学习模型。

*   **输入**：~500 候选
*   **输出**：带分数的 500 候选

## 4. 排序 (Ranking)：钱与博弈

**行业术语**：竞价排序 (Auction / Ranking)
**代码实现**：`4-ranking.service.ts`

算出了概率，怎么决定谁排第一？
这就涉及到了广告的核心商业逻辑——**eCPM (effective Cost Per Mille)**，即千次展示的期望收益。

不同的广告主有不同的出价模式：
*   **CPM**：我出钱买展示，风险广告主担。
*   **CPC**：我出钱买点击，平台要预估 pCTR。
*   **oCPM**：我出钱买转化，平台要预估 pCVR。

排序代码的核心，就是通过公式 $eCPM = Bid \times pCTR \times pCVR$ 把这些不同模式的广告拉到同一个维度上通过“钞能力”和“质量”进行公平竞争。

这也是博弈论（Game Theory）和机制设计（Mechanism Design）的战场，VCG 拍卖和 GSP 拍卖的理论就在这里落地。

*   **输入**：带分数的 500 候选
*   **输出**：按 eCPM 排序的列表

## 5. 重排序 (Rerank)：大局观

**行业术语**：重排 (Re-ranking)
**代码实现**：`5-rerank.service.ts`

如果你完全按 eCPM 排序，可能会出现一个问题：Top 10 的广告全是同一个土豪广告主的。这不仅用户体验极差，还会伤害平台的长期生态。

所以，我们需要最后一步“调整”。
我的代码在这里实现了**多样性控制**（同一个广告主最多出 2 个）和**截断**（只返回 Top 10）。在更复杂的系统里，这里还会加入 MMR 算法（最大边际相关性），在保证收益的同时，让推荐结果更多样化。

*   **输入**：排序后的列表
*   **输出**：最终 Top 10

## 总结

这次重构让我深刻体会到，所谓的“架构”，往往不是拍脑袋想出来的，而是被现实约束“逼”出来的。

广告引擎的漏斗架构，就是在海量数据（Retrieval）、业务约束（Filter）、精准预估（Prediction）、商业变现（Ranking）和生态健康（Rerank）之间寻找的那个**最优解**。

看着 `src/modules/engine/pipeline` 下的那几个文件，我仿佛看到的不是 TypeScript 代码，而是这几十年来计算广告行业凝结的智慧结晶。

下一步，我准备把 `Prediction` 里的随机数生成器换成一个真正的 ONNX 模型。既然骨架搭好了，是时候给它注入灵魂了。
